@misc{goodfellow2015explainingharnessingadversarialexamples,
      title={Explaining and Harnessing Adversarial Examples}, 
      author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
      year={2015},
      eprint={1412.6572},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1412.6572}, 
}

@misc{madry2019deeplearningmodelsresistant,
      title={Towards Deep Learning Models Resistant to Adversarial Attacks}, 
      author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
      year={2019},
      eprint={1706.06083},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1706.06083}, 
}

@ARTICLE{165600,
  author={Drucker, H. and Le Cun, Y.},
  journal={IEEE Transactions on Neural Networks}, 
  title={Improving generalization performance using double backpropagation}, 
  year={1992},
  volume={3},
  number={6},
  pages={991-997},
  keywords={Testing;Backpropagation algorithms;Jacobian matrices;Neurons;Signal to noise ratio;Neural networks},
  doi={10.1109/72.165600}
}

@misc{athalye2018obfuscatedgradientsfalsesense,
      title={Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples}, 
      author={Anish Athalye and Nicholas Carlini and David Wagner},
      year={2018},
      eprint={1802.00420},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1802.00420}, 
}

@misc{finlay2019scaleableinputgradientregularization,
      title={Scaleable input gradient regularization for adversarial robustness}, 
      author={Chris Finlay and Adam M Oberman},
      year={2019},
      eprint={1905.11468},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1905.11468}, 
}

@misc{simongabriel2019firstorderadversarialvulnerabilityneural,
      title={First-order Adversarial Vulnerability of Neural Networks and Input Dimension}, 
      author={Carl-Johann Simon-Gabriel and Yann Ollivier and Léon Bottou and Bernhard Schölkopf and David Lopez-Paz},
      year={2019},
      eprint={1802.01421},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1802.01421}, 
}

@misc{seck2019l1normdoublebackpropagation,
      title={L 1-norm double backpropagation adversarial defense}, 
      author={Ismaïla Seck and Gaëlle Loosli and Stephane Canu},
      year={2019},
      eprint={1903.01715},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1903.01715}, 
}

@misc{ross2017improvingadversarialrobustnessinterpretability,
      title={Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients}, 
      author={Andrew Slavin Ross and Finale Doshi-Velez},
      year={2017},
      eprint={1711.09404},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1711.09404}, 
}

@misc{papernot2017practicalblackboxattacksmachine,
      title={Practical Black-Box Attacks against Machine Learning}, 
      author={Nicolas Papernot and Patrick McDaniel and Ian Goodfellow and Somesh Jha and Z. Berkay Celik and Ananthram Swami},
      year={2017},
      eprint={1602.02697},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/1602.02697}, 
}

@misc{rodríguezmuñoz2024characterizingmodelrobustnessnatural,
      title={Characterizing Model Robustness via Natural Input Gradients}, 
      author={Adrián Rodríguez-Muñoz and Tongzhou Wang and Antonio Torralba},
      year={2024},
      eprint={2409.20139},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.20139}, 
}

@INPROCEEDINGS{7373334,
  author={Lyu, Chunchuan and Huang, Kaizhu and Liang, Hai-Ning},
  booktitle={2015 IEEE International Conference on Data Mining}, 
  title={A Unified Gradient Regularization Family for Adversarial Examples}, 
  year={2015},
  volume={},
  number={},
  pages={301-309},
  keywords={Robustness;Mathematical model;Predictive models;Approximation methods;Training;Data mining;Optimization;Adversarial examples;Deep learning;Regularization;Robust classification},
  doi={10.1109/ICDM.2015.84}
}

@misc{ororbia2016unifyingadversarialtrainingalgorithms,
      title={Unifying Adversarial Training Algorithms with Flexible Deep Data Gradient Regularization}, 
      author={Alexander G. Ororbia II and C. Lee Giles and Daniel Kifer},
      year={2016},
      eprint={1601.07213},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1601.07213}, 
}

@misc{kang2021understandingcatastrophicoverfittingadversarial,
      title={Understanding Catastrophic Overfitting in Adversarial Training}, 
      author={Peilin Kang and Seyed-Mohsen Moosavi-Dezfooli},
      year={2021},
      eprint={2105.02942},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2105.02942}, 
}

@misc{xie2021smoothadversarialtraining,
      title={Smooth Adversarial Training}, 
      author={Cihang Xie and Mingxing Tan and Boqing Gong and Alan Yuille and Quoc V. Le},
      year={2021},
      eprint={2006.14536},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2006.14536}, 
}

@misc{wong2020fastbetterfreerevisiting,
      title={Fast is better than free: Revisiting adversarial training}, 
      author={Eric Wong and Leslie Rice and J. Zico Kolter},
      year={2020},
      eprint={2001.03994},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2001.03994}, 
}

@misc{kim2020understandingcatastrophicoverfittingsinglestep,
      title={Understanding Catastrophic Overfitting in Single-step Adversarial Training}, 
      author={Hoki Kim and Woojin Lee and Jaewook Lee},
      year={2020},
      eprint={2010.01799},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2010.01799}, 
}

@misc{andriushchenko2020understandingimprovingfastadversarial,
      title={Understanding and Improving Fast Adversarial Training}, 
      author={Maksym Andriushchenko and Nicolas Flammarion},
      year={2020},
      eprint={2007.02617},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2007.02617}, 
}

@misc{moosavidezfooli2018robustnesscurvatureregularizationvice,
      title={Robustness via curvature regularization, and vice versa}, 
      author={Seyed-Mohsen Moosavi-Dezfooli and Alhussein Fawzi and Jonathan Uesato and Pascal Frossard},
      year={2018},
      eprint={1811.09716},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1811.09716}, 
}

@misc{singla2021lowcurvatureactivationsreduce,
      title={Low Curvature Activations Reduce Overfitting in Adversarial Training}, 
      author={Vasu Singla and Sahil Singla and David Jacobs and Soheil Feizi},
      year={2021},
      eprint={2102.07861},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2102.07861}, 
}

@misc{qin2019adversarialrobustnesslocallinearization,
      title={Adversarial Robustness through Local Linearization}, 
      author={Chongli Qin and James Martens and Sven Gowal and Dilip Krishnan and Krishnamurthy Dvijotham and Alhussein Fawzi and Soham De and Robert Stanforth and Pushmeet Kohli},
      year={2019},
      eprint={1907.02610},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1907.02610}, 
}

@misc{liu2023comprehensivestudyrobustnessimage,
      title={A Comprehensive Study on Robustness of Image Classification Models: Benchmarking and Rethinking}, 
      author={Chang Liu and Yinpeng Dong and Wenzhao Xiang and Xiao Yang and Hang Su and Jun Zhu and Yuefeng Chen and Yuan He and Hui Xue and Shibao Zheng},
      year={2023},
      eprint={2302.14301},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2302.14301}, 
}

@misc{croce2020reliableevaluationadversarialrobustness,
      title={Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks}, 
      author={Francesco Croce and Matthias Hein},
      year={2020},
      eprint={2003.01690},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2003.01690}, 
}